{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea3b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFERENCES\n",
    "\n",
    "# [1] https://www.tensorflow.org/federated/api_docs/python/tff/federated_computation\n",
    "# [2] TensorFlow Federated Tutorial Session, Google Tech Talk, Youtube, https://www.youtube.com/watch?v=JBNas6Yd30A\n",
    "\n",
    "# REQUIREMENTS\n",
    "\n",
    "# Might need to first install CMake\n",
    "# $ pip install CMake\n",
    "\n",
    "# tensorflow-federated: A Python open-source framework for machine learning and other computations on decentralized data.\n",
    "# $ pip install --upgrade tensorflow-federated\n",
    "\n",
    "# nest-asyncio: A Python module that patches asyncio to allow nested use of asyncio.run and loop.run_until_complete.\n",
    "# $ pip install --upgrade nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f33f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet --upgrade tensorflow-federated==0.20.0\n",
    "#!pip install --quiet --upgrade nest-asyncio\n",
    "\n",
    "# Local networking stuff. Cant run on Google Colab due to security reasons.\n",
    "# Allowing the nested use of asyncio.run and Loop.run_until_complete.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886a7ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard provides the visualization and tooling needed for machine learning experimentation\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61c4aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 17:03:53.626084: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-19 17:03:53.675772: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-19 17:03:53.676631: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 17:03:54.518436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "0.53.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# print(\"here\")\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "np.random.seed(0)\n",
    "# print(\"here\")\n",
    "# A Federated Computation (or FC) is a computation where the data stays on clients' machines [2]\n",
    "# This function simulates a federated computation given any python computation [1]\n",
    "#tff.federated_computation(lambda: 1+1)()\n",
    "# print(tff.federated_computation(lambda: 'Hello, World!')())\n",
    "\n",
    "\n",
    "# Federated Computations are made of three steps:\n",
    "#       1. Federated Broadcast: Publicly broadcast Global Model to clients.\n",
    "#       2. Federated Map: Privately train local parameters using private data and Global Model on the client-side.\n",
    "#       3. Federated Mean: Aggregate clients' locally trained parameters.\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tff.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2e8666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 17:03:57.325486: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-04-19 17:03:57.326390: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "E0419 17:03:57.456808100   19320 socket_utils_common_posix.cc:221] check for SO_REUSEPORT: {\"created\":\"@1681938237.456780500\",\"description\":\"Protocol not available\",\"errno\":92,\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/socket_utils_common_posix.cc\",\"file_line\":199,\"os_error\":\"Protocol not available\",\"syscall\":\"getsockopt(SO_REUSEPORT)\"}\n",
      "E0419 17:03:57.457247900   19320 socket_utils_common_posix.cc:327] setsockopt(TCP_USER_TIMEOUT) Protocol not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, World!'\n"
     ]
    }
   ],
   "source": [
    "# tff.backends.native.set_local_python_execution_context()\n",
    "print(tff.federated_computation(lambda: 'Hello, World!')())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759bb8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow_federated.python.simulation.datasets.client_data.PreprocessClientData'>\n"
     ]
    }
   ],
   "source": [
    "# Federated data is split amongst the clients and privately used in client-side Federated Mapping\n",
    "# To make things easy for demos, Tensorflow made MNIST into a federated data set by \n",
    "# keying the data by the original writer of the digits.\n",
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n",
    "\n",
    "print(type(emnist_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc7fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3383\n"
     ]
    }
   ],
   "source": [
    "# Client IDs can be accessed from the federated datasets\n",
    "client_ids = emnist_train.client_ids\n",
    "print(len(client_ids))\n",
    "# print(client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a96ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ParallelMapDataset element_spec=OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)), ('pixels', TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a single client's dataset from index 533\n",
    "# Returns a t\n",
    "client_dataset = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[533])\n",
    "\n",
    "# View the dataset's specs.\n",
    "# Specs will show the dataset holds labels and a single label is mapped to a pixels dataset with 28 rows and collumns.\n",
    "client_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2136d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 100\n",
    "PREFETCH_BUFFER = 10\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def batch_format_fn(element):\n",
    "    \n",
    "    return collections.OrderedDict(\n",
    "        # Reshape pixels for this Digit from a 28x28 2D array, into a 1D array with 784 pixels\n",
    "        # and return the (Label, [Pixels]) as an `OrderedDict`.\n",
    "        x=tf.reshape(element['pixels'], [-1, 784]),\n",
    "        y=tf.reshape(element['label'], [-1, 1]))\n",
    "  # Return reformated, batched, shuffled OrderedDicts of each Digit in the given client dataset\n",
    "  # prefetch is used to fetch a set of batches (10 in this case) in order to speed up the ML processing.\n",
    "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(\n",
    "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45cd24b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_ParallelMapDataset element_spec=OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)), ('pixels', TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])> <class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
     ]
    }
   ],
   "source": [
    "preprocessed_example_dataset = preprocess(client_dataset)\n",
    "\n",
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
    "                                     next(iter(preprocessed_example_dataset)))\n",
    "\n",
    "print(client_dataset, type(preprocessed_example_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94076086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_federated_data(client_data, client_ids):\n",
    "  return [\n",
    "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "      for x in client_ids\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa7f8989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow_federated.python.simulation.datasets.client_data.PreprocessClientData object at 0x7f63b3e3a5b0>\n",
      "Number of client datasets: 10\n",
      "Set of OrderedDicts: [<_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <_PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>]\n"
     ]
    }
   ],
   "source": [
    "# Sample of 10 clients\n",
    "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
    "# \n",
    "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
    "print(emnist_train)\n",
    "print(f'Number of client datasets: {len(federated_train_data)}')\n",
    "print(f'Set of OrderedDicts: {federated_train_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "294ab890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
    "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
    "      tf.keras.layers.Softmax(),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8957ac80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(training_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a569bb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)),\n",
       "             ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_state = training_process.initialize()\n",
    "preprocessed_example_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "091de057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tff.learning.Model interface [https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model]\n",
    "# \n",
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "  keras_model = create_keras_model()\n",
    "  # wrap in an instance of the tff.learning.Model interface\n",
    "  return tff.learning.models.from_keras_model( \n",
    "      keras_model,\n",
    "      input_spec=preprocessed_example_dataset.element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e83a863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 17:04:00.188567: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'args_2' with dtype int32 and shape [?,1]\n",
      "\t [[{{node args_2}}]]\n"
     ]
    }
   ],
   "source": [
    "# The Federated Averaging algorithm below, there are 2 optimizers: a _clientoptimizer and a _serveroptimizer.\n",
    "# _clientoptimizer is only used to compute local model updates on each client.\n",
    "# _serveroptimizer applies the averaged update to the global model at the server.\n",
    "# We can experiment with different learning rates, but the idea is that clients can be simulated to have a lower learning rate.\n",
    "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
    "\n",
    "# TFF has constructed 2 federated computations and packaged them into a tff.templates.IterativeProcess [https://www.tensorflow.org/federated/api_docs/python/tff/templates/IterativeProcess]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c63d9571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[784,10],\n",
      "      float32[10]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64,\n",
      "    float32[784,10],\n",
      "    float32[10]\n",
      "  >\n",
      ">@SERVER)\n",
      "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=[0, array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)])\n"
     ]
    }
   ],
   "source": [
    "print(training_process.initialize.type_signature.formatted_representation())\n",
    "\n",
    "\n",
    "train_state = training_process.initialize()\n",
    "print(train_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc38e84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.12345679), ('loss', 3.1193738), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
     ]
    }
   ],
   "source": [
    "# \".next()\" is used to run a single round of a Federated Computation.\n",
    "result = training_process.next(train_state, federated_train_data)\n",
    "train_state = result.state\n",
    "train_metrics = result.metrics\n",
    "\n",
    "# Essentially, a Federated Computation is described in the context of a simulation,\n",
    "# as an initial state of the total system [Server_State, Federated Data],\n",
    "# And a transformation into a new state of the total system [Server_State, Training Metrics]\n",
    "print('round  1, metrics={}'.format(train_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "611c3016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[ 0.00024632, -0.00793567,  0.0009302 , ..., -0.00296105,\n",
      "         0.00211118,  0.00075989],\n",
      "       [ 0.00024632, -0.00793567,  0.0009302 , ..., -0.00296105,\n",
      "         0.00211118,  0.00075989],\n",
      "       [ 0.00024632, -0.00793567,  0.0009302 , ..., -0.00296105,\n",
      "         0.00211118,  0.00075989],\n",
      "       ...,\n",
      "       [ 0.00024632, -0.00793567,  0.0009302 , ..., -0.00296105,\n",
      "         0.00211118,  0.00075989],\n",
      "       [ 0.00024632, -0.00793567,  0.0009302 , ..., -0.00296105,\n",
      "         0.00211118,  0.00075989],\n",
      "       [ 0.00024632, -0.00793567,  0.0009302 , ..., -0.00296105,\n",
      "         0.00211118,  0.00075989]], dtype=float32), array([ 0.00024632, -0.00793567,  0.0009302 ,  0.00116791,  0.00171909,\n",
      "        0.00160558,  0.00235655, -0.00296105,  0.00211118,  0.00075989],\n",
      "      dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=[11, array([[-2.1172564e-05, -6.2619196e-04,  8.2008701e-05, ...,\n",
      "        -9.2198425e-05,  2.7616206e-04,  9.0202237e-05],\n",
      "       [-2.1172564e-05, -6.2619196e-04,  8.2008701e-05, ...,\n",
      "        -9.2198425e-05,  2.7616206e-04,  9.0202237e-05],\n",
      "       [-2.1172564e-05, -6.2619196e-04,  8.2008701e-05, ...,\n",
      "        -9.2198425e-05,  2.7616206e-04,  9.0202237e-05],\n",
      "       ...,\n",
      "       [-2.1172564e-05, -6.2619196e-04,  8.2008701e-05, ...,\n",
      "        -9.2198425e-05,  2.7616206e-04,  9.0202237e-05],\n",
      "       [-2.1172380e-05, -6.2619225e-04,  8.2009014e-05, ...,\n",
      "        -9.2198869e-05,  2.7616185e-04,  9.0202753e-05],\n",
      "       [-2.1172380e-05, -6.2619225e-04,  8.2009014e-05, ...,\n",
      "        -9.2198869e-05,  2.7616185e-04,  9.0202753e-05]], dtype=float32), array([-2.1172564e-05, -6.2619196e-04,  8.2008701e-05,  6.4824257e-05,\n",
      "        2.2040571e-05,  1.7619108e-04,  2.8133729e-05, -9.2198425e-05,\n",
      "        2.7616206e-04,  9.0202237e-05], dtype=float32)])\n",
      "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.34609053), ('loss', 1.983079), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[ 0.00022119, -0.00854164,  0.00101641, ..., -0.00303362,\n",
      "         0.00236997,  0.00086525],\n",
      "       [ 0.00022119, -0.00854164,  0.00101641, ..., -0.00303362,\n",
      "         0.00236997,  0.00086525],\n",
      "       [ 0.00022119, -0.00854164,  0.00101641, ..., -0.00303362,\n",
      "         0.00236997,  0.00086525],\n",
      "       ...,\n",
      "       [ 0.00022119, -0.00854164,  0.00101641, ..., -0.00303362,\n",
      "         0.00236997,  0.00086525],\n",
      "       [ 0.00022118, -0.00854164,  0.00101641, ..., -0.00303362,\n",
      "         0.00236997,  0.00086525],\n",
      "       [ 0.00022118, -0.00854164,  0.00101641, ..., -0.00303362,\n",
      "         0.00236997,  0.00086525]], dtype=float32), array([ 0.00022119, -0.00854164,  0.00101641,  0.00122728,  0.00173611,\n",
      "        0.00177203,  0.00236704, -0.00303362,  0.00236997,  0.00086525],\n",
      "      dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=[12, array([[-2.51375222e-05, -6.05965324e-04,  8.62117886e-05, ...,\n",
      "        -7.25741775e-05,  2.58784974e-04,  1.05354426e-04],\n",
      "       [-2.51375222e-05, -6.05965324e-04,  8.62117886e-05, ...,\n",
      "        -7.25741775e-05,  2.58784974e-04,  1.05354426e-04],\n",
      "       [-2.51375222e-05, -6.05965324e-04,  8.62117886e-05, ...,\n",
      "        -7.25741775e-05,  2.58784974e-04,  1.05354426e-04],\n",
      "       ...,\n",
      "       [-2.51375222e-05, -6.05965324e-04,  8.62117886e-05, ...,\n",
      "        -7.25741775e-05,  2.58784974e-04,  1.05354426e-04],\n",
      "       [-2.51374622e-05, -6.05965266e-04,  8.62118977e-05, ...,\n",
      "        -7.25751524e-05,  2.58784828e-04,  1.05355160e-04],\n",
      "       [-2.51374622e-05, -6.05965266e-04,  8.62118977e-05, ...,\n",
      "        -7.25751524e-05,  2.58784828e-04,  1.05355160e-04]], dtype=float32), array([-2.51375222e-05, -6.05965324e-04,  8.62117886e-05,  5.93695113e-05,\n",
      "        1.70239691e-05,  1.66448430e-04,  1.04847759e-05, -7.25741775e-05,\n",
      "        2.58784974e-04,  1.05354426e-04], dtype=float32)])\n",
      "round  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.37037036), ('loss', 1.9001011), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[ 0.00020144, -0.0091233 ,  0.00110535, ..., -0.00311031,\n",
      "         0.0026179 ,  0.0009701 ],\n",
      "       [ 0.00020144, -0.0091233 ,  0.00110535, ..., -0.00311031,\n",
      "         0.0026179 ,  0.0009701 ],\n",
      "       [ 0.00020144, -0.0091233 ,  0.00110535, ..., -0.00311031,\n",
      "         0.0026179 ,  0.0009701 ],\n",
      "       ...,\n",
      "       [ 0.00020144, -0.0091233 ,  0.00110535, ..., -0.00311031,\n",
      "         0.0026179 ,  0.0009701 ],\n",
      "       [ 0.00020144, -0.0091233 ,  0.00110534, ..., -0.00311031,\n",
      "         0.0026179 ,  0.0009701 ],\n",
      "       [ 0.00020144, -0.0091233 ,  0.00110534, ..., -0.00311031,\n",
      "         0.0026179 ,  0.0009701 ]], dtype=float32), array([ 0.00020144, -0.0091233 ,  0.00110535,  0.0012854 ,  0.00174887,\n",
      "        0.00192957,  0.002375  , -0.00311031,  0.0026179 ,  0.0009701 ],\n",
      "      dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=[13, array([[-1.97406662e-05, -5.81666187e-04,  8.89349249e-05, ...,\n",
      "        -7.66851008e-05,  2.47929042e-04,  1.04852246e-04],\n",
      "       [-1.97406662e-05, -5.81666187e-04,  8.89349249e-05, ...,\n",
      "        -7.66851008e-05,  2.47929042e-04,  1.04852246e-04],\n",
      "       [-1.97406662e-05, -5.81666187e-04,  8.89349249e-05, ...,\n",
      "        -7.66851008e-05,  2.47929042e-04,  1.04852246e-04],\n",
      "       ...,\n",
      "       [-1.97406662e-05, -5.81666187e-04,  8.89349249e-05, ...,\n",
      "        -7.66851008e-05,  2.47929042e-04,  1.04852246e-04],\n",
      "       [-1.97409227e-05, -5.81666187e-04,  8.89344738e-05, ...,\n",
      "        -7.66852027e-05,  2.47929478e-04,  1.04852348e-04],\n",
      "       [-1.97409227e-05, -5.81666187e-04,  8.89344738e-05, ...,\n",
      "        -7.66852027e-05,  2.47929478e-04,  1.04852348e-04]], dtype=float32), array([-1.97406662e-05, -5.81666187e-04,  8.89349249e-05,  5.81186541e-05,\n",
      "        1.27629246e-05,  1.57533330e-04,  7.96096720e-06, -7.66851008e-05,\n",
      "        2.47929042e-04,  1.04852246e-04], dtype=float32)])\n",
      "round  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.39773664), ('loss', 1.8232777), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[ 0.00018691, -0.00968043,  0.00119516, ..., -0.00319476,\n",
      "         0.00286274,  0.0010699 ],\n",
      "       [ 0.00018691, -0.00968043,  0.00119516, ..., -0.00319476,\n",
      "         0.00286274,  0.0010699 ],\n",
      "       [ 0.00018691, -0.00968043,  0.00119516, ..., -0.00319476,\n",
      "         0.00286274,  0.0010699 ],\n",
      "       ...,\n",
      "       [ 0.00018691, -0.00968043,  0.00119516, ..., -0.00319476,\n",
      "         0.00286274,  0.0010699 ],\n",
      "       [ 0.0001869 , -0.00968043,  0.00119515, ..., -0.00319476,\n",
      "         0.00286273,  0.0010699 ],\n",
      "       [ 0.0001869 , -0.00968043,  0.00119515, ..., -0.00319476,\n",
      "         0.00286273,  0.0010699 ]], dtype=float32), array([ 0.00018691, -0.00968043,  0.00119516,  0.00134561,  0.00175466,\n",
      "        0.00207815,  0.00238208, -0.00319476,  0.00286274,  0.0010699 ],\n",
      "      dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=[14, array([[-1.4538542e-05, -5.5712654e-04,  8.9811598e-05, ...,\n",
      "        -8.4450214e-05,  2.4484127e-04,  9.9805082e-05],\n",
      "       [-1.4538542e-05, -5.5712654e-04,  8.9811598e-05, ...,\n",
      "        -8.4450214e-05,  2.4484127e-04,  9.9805082e-05],\n",
      "       [-1.4538542e-05, -5.5712654e-04,  8.9811598e-05, ...,\n",
      "        -8.4450214e-05,  2.4484127e-04,  9.9805082e-05],\n",
      "       ...,\n",
      "       [-1.4538542e-05, -5.5712654e-04,  8.9811598e-05, ...,\n",
      "        -8.4450214e-05,  2.4484127e-04,  9.9805082e-05],\n",
      "       [-1.4539057e-05, -5.5712636e-04,  8.9811074e-05, ...,\n",
      "        -8.4449777e-05,  2.4483958e-04,  9.9804958e-05],\n",
      "       [-1.4539057e-05, -5.5712636e-04,  8.9811074e-05, ...,\n",
      "        -8.4449777e-05,  2.4483958e-04,  9.9804958e-05]], dtype=float32), array([-1.4538542e-05, -5.5712654e-04,  8.9811598e-05,  6.0213777e-05,\n",
      "        5.7826805e-06,  1.4858505e-04,  7.0764145e-06, -8.4450214e-05,\n",
      "        2.4484127e-04,  9.9805082e-05], dtype=float32)])\n",
      "round  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.42098767), ('loss', 1.7517612), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[ 0.00017442, -0.01021456,  0.00128478, ..., -0.00328444,\n",
      "         0.00310908,  0.00116567],\n",
      "       [ 0.00017442, -0.01021456,  0.00128478, ..., -0.00328444,\n",
      "         0.00310908,  0.00116567],\n",
      "       [ 0.00017442, -0.01021456,  0.00128478, ..., -0.00328444,\n",
      "         0.00310908,  0.00116567],\n",
      "       ...,\n",
      "       [ 0.00017442, -0.01021456,  0.00128478, ..., -0.00328444,\n",
      "         0.00310908,  0.00116567],\n",
      "       [ 0.00017442, -0.01021456,  0.00128478, ..., -0.00328444,\n",
      "         0.00310908,  0.00116567],\n",
      "       [ 0.00017442, -0.01021456,  0.00128478, ..., -0.00328444,\n",
      "         0.00310908,  0.00116567]], dtype=float32), array([ 0.00017442, -0.01021456,  0.00128478,  0.00141035,  0.00175132,\n",
      "        0.00221735,  0.00238604, -0.00328444,  0.00310908,  0.00116567],\n",
      "      dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=[15, array([[-1.2487222e-05, -5.3412974e-04,  8.9624402e-05, ...,\n",
      "        -8.9685025e-05,  2.4634399e-04,  9.5770483e-05],\n",
      "       [-1.2487222e-05, -5.3412974e-04,  8.9624402e-05, ...,\n",
      "        -8.9685025e-05,  2.4634399e-04,  9.5770483e-05],\n",
      "       [-1.2487222e-05, -5.3412974e-04,  8.9624402e-05, ...,\n",
      "        -8.9685025e-05,  2.4634399e-04,  9.5770483e-05],\n",
      "       ...,\n",
      "       [-1.2487222e-05, -5.3412974e-04,  8.9624402e-05, ...,\n",
      "        -8.9685025e-05,  2.4634399e-04,  9.5770483e-05],\n",
      "       [-1.2487419e-05, -5.3413038e-04,  8.9624606e-05, ...,\n",
      "        -8.9685469e-05,  2.4634466e-04,  9.5770585e-05],\n",
      "       [-1.2487419e-05, -5.3413038e-04,  8.9624606e-05, ...,\n",
      "        -8.9685469e-05,  2.4634466e-04,  9.5770585e-05]], dtype=float32), array([-1.2487222e-05, -5.3412974e-04,  8.9624402e-05,  6.4734362e-05,\n",
      "       -3.3353338e-06,  1.3919626e-04,  3.9680504e-06, -8.9685025e-05,\n",
      "        2.4634399e-04,  9.5770483e-05], dtype=float32)])\n",
      "round  6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.44485596), ('loss', 1.6847681), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[ 0.00016229, -0.01072698,  0.00137428, ..., -0.00337671,\n",
      "         0.00335575,  0.00125884],\n",
      "       [ 0.00016229, -0.01072698,  0.00137428, ..., -0.00337671,\n",
      "         0.00335575,  0.00125884],\n",
      "       [ 0.00016229, -0.01072698,  0.00137428, ..., -0.00337671,\n",
      "         0.00335575,  0.00125884],\n",
      "       ...,\n",
      "       [ 0.00016229, -0.01072698,  0.00137428, ..., -0.00337671,\n",
      "         0.00335575,  0.00125884],\n",
      "       [ 0.00016229, -0.01072699,  0.00137428, ..., -0.00337671,\n",
      "         0.00335574,  0.00125884],\n",
      "       [ 0.00016229, -0.01072699,  0.00137428, ..., -0.00337671,\n",
      "         0.00335574,  0.00125884]], dtype=float32), array([ 0.00016229, -0.01072698,  0.00137428,  0.0014788 ,  0.00174047,\n",
      "        0.00234791,  0.00238536, -0.00337671,  0.00335575,  0.00125884],\n",
      "      dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=[16, array([[-1.2127153e-05, -5.1242660e-04,  8.9502711e-05, ...,\n",
      "        -9.2267379e-05,  2.4666439e-04,  9.3169612e-05],\n",
      "       [-1.2127153e-05, -5.1242660e-04,  8.9502711e-05, ...,\n",
      "        -9.2267379e-05,  2.4666439e-04,  9.3169612e-05],\n",
      "       [-1.2127153e-05, -5.1242660e-04,  8.9502711e-05, ...,\n",
      "        -9.2267379e-05,  2.4666439e-04,  9.3169612e-05],\n",
      "       ...,\n",
      "       [-1.2127153e-05, -5.1242660e-04,  8.9502711e-05, ...,\n",
      "        -9.2267379e-05,  2.4666439e-04,  9.3169612e-05],\n",
      "       [-1.2128233e-05, -5.1242701e-04,  8.9502828e-05, ...,\n",
      "        -9.2267328e-05,  2.4666390e-04,  9.3170180e-05],\n",
      "       [-1.2128233e-05, -5.1242701e-04,  8.9502828e-05, ...,\n",
      "        -9.2267328e-05,  2.4666390e-04,  9.3170180e-05]], dtype=float32), array([-1.2127153e-05, -5.1242660e-04,  8.9502711e-05,  6.8451263e-05,\n",
      "       -1.0847039e-05,  1.3056297e-04, -6.8193970e-07, -9.2267379e-05,\n",
      "        2.4666439e-04,  9.3169612e-05], dtype=float32)])\n",
      "round  7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.47037038), ('loss', 1.621765), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[ 0.00014995, -0.01121885,  0.00146384, ..., -0.00347031,\n",
      "         0.00360016,  0.00135025],\n",
      "       [ 0.00014995, -0.01121885,  0.00146384, ..., -0.00347031,\n",
      "         0.00360016,  0.00135025],\n",
      "       [ 0.00014995, -0.01121885,  0.00146384, ..., -0.00347031,\n",
      "         0.00360016,  0.00135025],\n",
      "       ...,\n",
      "       [ 0.00014995, -0.01121885,  0.00146384, ..., -0.00347031,\n",
      "         0.00360016,  0.00135025],\n",
      "       [ 0.00014995, -0.01121885,  0.00146384, ..., -0.00347031,\n",
      "         0.00360015,  0.00135025],\n",
      "       [ 0.00014995, -0.01121885,  0.00146384, ..., -0.00347031,\n",
      "         0.00360015,  0.00135025]], dtype=float32), array([ 0.00014995, -0.01121885,  0.00146384,  0.00154881,  0.00172487,\n",
      "        0.00247164,  0.00237966, -0.00347031,  0.00360016,  0.00135025],\n",
      "      dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=[17, array([[-1.2341216e-05, -4.9186399e-04,  8.9556044e-05, ...,\n",
      "        -9.3604409e-05,  2.4441045e-04,  9.1403206e-05],\n",
      "       [-1.2341216e-05, -4.9186399e-04,  8.9556044e-05, ...,\n",
      "        -9.3604409e-05,  2.4441045e-04,  9.1403206e-05],\n",
      "       [-1.2341216e-05, -4.9186399e-04,  8.9556044e-05, ...,\n",
      "        -9.3604409e-05,  2.4441045e-04,  9.1403206e-05],\n",
      "       ...,\n",
      "       [-1.2341216e-05, -4.9186399e-04,  8.9556044e-05, ...,\n",
      "        -9.3604409e-05,  2.4441045e-04,  9.1403206e-05],\n",
      "       [-1.2341669e-05, -4.9186440e-04,  8.9555906e-05, ...,\n",
      "        -9.3604904e-05,  2.4441068e-04,  9.1403897e-05],\n",
      "       [-1.2341669e-05, -4.9186440e-04,  8.9555906e-05, ...,\n",
      "        -9.3604904e-05,  2.4441068e-04,  9.1403897e-05]], dtype=float32), array([-1.2341216e-05, -4.9186399e-04,  8.9556044e-05,  7.0010596e-05,\n",
      "       -1.5602116e-05,  1.2372907e-04, -5.6972476e-06, -9.3604409e-05,\n",
      "        2.4441045e-04,  9.1403206e-05], dtype=float32)])\n",
      "round  8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.49218106), ('loss', 1.562412), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[ 0.00013706, -0.01169143,  0.00155345, ..., -0.00356527,\n",
      "         0.00384129,  0.00144036],\n",
      "       [ 0.00013706, -0.01169143,  0.00155345, ..., -0.00356527,\n",
      "         0.00384129,  0.00144036],\n",
      "       [ 0.00013706, -0.01169143,  0.00155345, ..., -0.00356527,\n",
      "         0.00384129,  0.00144036],\n",
      "       ...,\n",
      "       [ 0.00013706, -0.01169143,  0.00155345, ..., -0.00356527,\n",
      "         0.00384129,  0.00144036],\n",
      "       [ 0.00013706, -0.01169143,  0.00155345, ..., -0.00356527,\n",
      "         0.00384129,  0.00144036],\n",
      "       [ 0.00013706, -0.01169143,  0.00155345, ..., -0.00356527,\n",
      "         0.00384129,  0.00144036]], dtype=float32), array([ 0.00013706, -0.01169143,  0.00155345,  0.00161861,  0.00170608,\n",
      "        0.00259041,  0.00236944, -0.00356527,  0.00384129,  0.00144036],\n",
      "      dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=[18, array([[-1.2888670e-05, -4.7257770e-04,  8.9611778e-05, ...,\n",
      "        -9.4955205e-05,  2.4113402e-04,  9.0115158e-05],\n",
      "       [-1.2888670e-05, -4.7257770e-04,  8.9611778e-05, ...,\n",
      "        -9.4955205e-05,  2.4113402e-04,  9.0115158e-05],\n",
      "       [-1.2888670e-05, -4.7257770e-04,  8.9611778e-05, ...,\n",
      "        -9.4955205e-05,  2.4113402e-04,  9.0115158e-05],\n",
      "       ...,\n",
      "       [-1.2888670e-05, -4.7257770e-04,  8.9611778e-05, ...,\n",
      "        -9.4955205e-05,  2.4113402e-04,  9.0115158e-05],\n",
      "       [-1.2887922e-05, -4.7257682e-04,  8.9611247e-05, ...,\n",
      "        -9.4954812e-05,  2.4113405e-04,  9.0115085e-05],\n",
      "       [-1.2887922e-05, -4.7257682e-04,  8.9611247e-05, ...,\n",
      "        -9.4954812e-05,  2.4113405e-04,  9.0115085e-05]], dtype=float32), array([-1.2888670e-05, -4.7257770e-04,  8.9611778e-05,  6.9805719e-05,\n",
      "       -1.8789984e-05,  1.1877327e-04, -1.0228580e-05, -9.4955205e-05,\n",
      "        2.4113402e-04,  9.0115158e-05], dtype=float32)])\n",
      "round  9, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.51316875), ('loss', 1.5064504), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "LearningAlgorithmState(global_model_weights=ModelWeights(trainable=[array([[ 0.00012347, -0.01214606,  0.00164301, ..., -0.00366197,\n",
      "         0.00407896,  0.00152956],\n",
      "       [ 0.00012347, -0.01214606,  0.00164301, ..., -0.00366197,\n",
      "         0.00407896,  0.00152956],\n",
      "       [ 0.00012347, -0.01214606,  0.00164301, ..., -0.00366197,\n",
      "         0.00407896,  0.00152956],\n",
      "       ...,\n",
      "       [ 0.00012347, -0.01214606,  0.00164301, ..., -0.00366197,\n",
      "         0.00407896,  0.00152956],\n",
      "       [ 0.00012347, -0.01214606,  0.00164301, ..., -0.00366197,\n",
      "         0.00407896,  0.00152956],\n",
      "       [ 0.00012347, -0.01214606,  0.00164301, ..., -0.00366197,\n",
      "         0.00407896,  0.00152956]], dtype=float32), array([ 0.00012347, -0.01214606,  0.00164301,  0.00168713,  0.00168478,\n",
      "        0.00270546,  0.00235567, -0.00366197,  0.00407896,  0.00152956],\n",
      "      dtype=float32)], non_trainable=[]), distributor=(), client_work=(), aggregator=OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())]), finalizer=[19, array([[-1.35929740e-05, -4.54630033e-04,  8.95603298e-05, ...,\n",
      "        -9.67023807e-05,  2.37670843e-04,  8.92014650e-05],\n",
      "       [-1.35929740e-05, -4.54630033e-04,  8.95603298e-05, ...,\n",
      "        -9.67023807e-05,  2.37670843e-04,  8.92014650e-05],\n",
      "       [-1.35929740e-05, -4.54630033e-04,  8.95603298e-05, ...,\n",
      "        -9.67023807e-05,  2.37670843e-04,  8.92014650e-05],\n",
      "       ...,\n",
      "       [-1.35929740e-05, -4.54630033e-04,  8.95603298e-05, ...,\n",
      "        -9.67023807e-05,  2.37670843e-04,  8.92014650e-05],\n",
      "       [-1.35929495e-05, -4.54630383e-04,  8.95600606e-05, ...,\n",
      "        -9.67020605e-05,  2.37671295e-04,  8.92018070e-05],\n",
      "       [-1.35929495e-05, -4.54630383e-04,  8.95600606e-05, ...,\n",
      "        -9.67020605e-05,  2.37671295e-04,  8.92018070e-05]], dtype=float32), array([-1.3592974e-05, -4.5463003e-04,  8.9560330e-05,  6.8512476e-05,\n",
      "       -2.1296617e-05,  1.1504582e-04, -1.3768188e-05, -9.6702381e-05,\n",
      "        2.3767084e-04,  8.9201465e-05], dtype=float32)])\n",
      "round 10, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5314815), ('loss', 1.4536941), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
     ]
    }
   ],
   "source": [
    "# For our implementation, it would be a challenge to pick randomly selected datasets, to simulate real world interactions.\n",
    "\n",
    "NUM_ROUNDS = 11\n",
    "# Just running the above Federated Computation 11 times, using .next()\n",
    "# As you can see the system converges to a higher level of accuracy with each round.\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "  result = training_process.next(train_state, federated_train_data)\n",
    "  train_state = result.state\n",
    "  train_metrics = result.metrics\n",
    "  print(train_state)\n",
    "  print('round {:2d}, metrics={}'.format(round_num, train_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b707b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
