{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea3b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFERENCES\n",
    "\n",
    "# [1] https://www.tensorflow.org/federated/api_docs/python/tff/federated_computation\n",
    "# [2] TensorFlow Federated Tutorial Session, Google Tech Talk, Youtube, https://www.youtube.com/watch?v=JBNas6Yd30A\n",
    "\n",
    "# REQUIREMENTS\n",
    "\n",
    "# Might need to first install CMake\n",
    "# $ pip install CMake\n",
    "\n",
    "# tensorflow-federated: A Python open-source framework for machine learning and other computations on decentralized data.\n",
    "# $ pip install --upgrade tensorflow-federated\n",
    "\n",
    "# nest-asyncio: A Python module that patches asyncio to allow nested use of asyncio.run and loop.run_until_complete.\n",
    "# $ pip install --upgrade nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f33f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet --upgrade tensorflow-federated==0.20.0\n",
    "#!pip install --quiet --upgrade nest-asyncio\n",
    "\n",
    "# Local networking stuff. Cant run on Google Colab due to security reasons.\n",
    "# Allowing the nested use of asyncio.run and Loop.run_until_complete.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886a7ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard provides the visualization and tooling needed for machine learning experimentation\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61c4aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 18:35:49.295132: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-12 18:35:49.344879: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-12 18:35:49.345763: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-12 18:35:50.181200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "0.53.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# print(\"here\")\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "np.random.seed(0)\n",
    "# print(\"here\")\n",
    "# A Federated Computation (or FC) is a computation where the data stays on clients' machines [2]\n",
    "# This function simulates a federated computation given any python computation [1]\n",
    "#tff.federated_computation(lambda: 1+1)()\n",
    "# print(tff.federated_computation(lambda: 'Hello, World!')())\n",
    "\n",
    "\n",
    "# Federated Computations are made of three steps:\n",
    "#       1. Federated Broadcast: Publicly broadcast Global Model to clients.\n",
    "#       2. Federated Map: Privately train local parameters using private data and Global Model on the client-side.\n",
    "#       3. Federated Mean: Aggregate clients' locally trained parameters.\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tff.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2e8666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 18:35:52.792400: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-04-12 18:35:52.792989: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "E0412 18:35:52.924944400     424 socket_utils_common_posix.cc:221] check for SO_REUSEPORT: {\"created\":\"@1681338952.924914900\",\"description\":\"Protocol not available\",\"errno\":92,\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/socket_utils_common_posix.cc\",\"file_line\":199,\"os_error\":\"Protocol not available\",\"syscall\":\"getsockopt(SO_REUSEPORT)\"}\n",
      "E0412 18:35:52.925516700     424 socket_utils_common_posix.cc:327] setsockopt(TCP_USER_TIMEOUT) Protocol not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, World!'\n"
     ]
    }
   ],
   "source": [
    "# tff.backends.native.set_local_python_execution_context()\n",
    "print(tff.federated_computation(lambda: 'Hello, World!')())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "759bb8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow_federated.python.simulation.datasets.client_data.PreprocessClientData'>\n"
     ]
    }
   ],
   "source": [
    "# Federated data is split amongst the clients and privately used in client-side Federated Mapping\n",
    "# To make things easy for demos, Tensorflow made MNIST into a federated data set by \n",
    "# keying the data by the original writer of the digits.\n",
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n",
    "\n",
    "print(type(emnist_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc7fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3383\n"
     ]
    }
   ],
   "source": [
    "# Client IDs can be accessed from the federated datasets\n",
    "client_ids = emnist_train.client_ids\n",
    "print(len(client_ids))\n",
    "# print(client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a96ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)),\n",
       "             ('pixels',\n",
       "              TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a single client's dataset from index 533\n",
    "# Returns a t\n",
    "client_dataset = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[533])\n",
    "\n",
    "# View the dataset's specs.\n",
    "# Specs will show the dataset holds labels and a single label is mapped to a pixels dataset with 28 rows and collumns.\n",
    "client_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2136d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 100\n",
    "PREFETCH_BUFFER = 10\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def batch_format_fn(element):\n",
    "    \n",
    "    return collections.OrderedDict(\n",
    "        # Reshape pixels for this Digit from a 28x28 2D array, into a 1D array with 784 pixels\n",
    "        # and return the (Label, [Pixels]) as an `OrderedDict`.\n",
    "        x=tf.reshape(element['pixels'], [-1, 784]),\n",
    "        y=tf.reshape(element['label'], [-1, 1]))\n",
    "  # Return reformated, batched, shuffled OrderedDicts of each Digit in the given client dataset\n",
    "  # prefetch is used to fetch a set of batches (10 in this case) in order to speed up the ML processing.\n",
    "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(\n",
    "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45cd24b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'> <class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
     ]
    }
   ],
   "source": [
    "preprocessed_example_dataset = preprocess(client_dataset)\n",
    "\n",
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
    "                                     next(iter(preprocessed_example_dataset)))\n",
    "\n",
    "print(type(sample_batch), type(preprocessed_example_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94076086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_federated_data(client_data, client_ids):\n",
    "  return [\n",
    "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "      for x in client_ids\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa7f8989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of client datasets: 10\n",
      "Set of OrderedDicts: [<PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>, <PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))])>]\n"
     ]
    }
   ],
   "source": [
    "# Sample of 10 clients\n",
    "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
    "# \n",
    "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
    "\n",
    "print(f'Number of client datasets: {len(federated_train_data)}')\n",
    "print(f'Set of OrderedDicts: {federated_train_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "294ab890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
    "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
    "      tf.keras.layers.Softmax(),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8957ac80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[784,10],\n",
      "      float32[10]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64,\n",
      "    float32[784,10],\n",
      "    float32[10]\n",
      "  >\n",
      ">@SERVER)\n"
     ]
    }
   ],
   "source": [
    "print(training_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a569bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_state = training_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "091de057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tff.learning.Model interface [https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model]\n",
    "# \n",
    "def model_fn():\n",
    "    # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "  keras_model = create_keras_model()\n",
    "  # wrap in an instance of the tff.learning.Model interface\n",
    "  return tff.learning.from_keras_model( \n",
    "      keras_model,\n",
    "      input_spec=preprocessed_example_dataset.element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e83a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Federated Averaging algorithm below, there are 2 optimizers: a _clientoptimizer and a _serveroptimizer.\n",
    "# _clientoptimizer is only used to compute local model updates on each client.\n",
    "# _serveroptimizer applies the averaged update to the global model at the server.\n",
    "# We can experiment with different learning rates, but the idea is that clients can be simulated to have a lower learning rate.\n",
    "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
    "\n",
    "# TFF has constructed 2 federated computations and packaged them into a tff.templates.IterativeProcess [https://www.tensorflow.org/federated/api_docs/python/tff/templates/IterativeProcess]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c63d9571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[784,10],\n",
      "      float32[10]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64,\n",
      "    float32[784,10],\n",
      "    float32[10]\n",
      "  >\n",
      ">@SERVER)\n"
     ]
    }
   ],
   "source": [
    "print(training_process.initialize.type_signature.formatted_representation())\n",
    "\n",
    "\n",
    "train_state = training_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc38e84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.12345679), ('loss', 3.1193738), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
     ]
    }
   ],
   "source": [
    "# \".next()\" is used to run a single round of a Federated Computation.\n",
    "result = training_process.next(train_state, federated_train_data)\n",
    "train_state = result.state\n",
    "train_metrics = result.metrics\n",
    "\n",
    "# Essentially, a Federated Computation is described in the context of a simulation,\n",
    "# as an initial state of the total system [Server_State, Federated Data],\n",
    "# And a transformation into a new state of the total system [Server_State, Training Metrics]\n",
    "print('round  1, metrics={}'.format(train_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "611c3016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.13518518), ('loss', 2.9834733), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "round  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.14382716), ('loss', 2.861665), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "round  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.17407407), ('loss', 2.7957022), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "round  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.19917695), ('loss', 2.614657), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "round  6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.21975309), ('loss', 2.529761), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "round  7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.2409465), ('loss', 2.4053502), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "round  8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.2611111), ('loss', 2.3153892), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "round  9, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.30823046), ('loss', 2.1240263), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
      "round 10, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.33312756), ('loss', 2.1164267), ('num_examples', 4860), ('num_batches', 248)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
     ]
    }
   ],
   "source": [
    "# For our implementation, it would be a challenge to pick randomly selected datasets, to simulate real world interactions.\n",
    "\n",
    "NUM_ROUNDS = 11\n",
    "# Just running the above Federated Computation 11 times, using .next()\n",
    "# As you can see the system converges to a higher level of accuracy with each round.\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "  result = training_process.next(train_state, federated_train_data)\n",
    "  train_state = result.state\n",
    "  train_metrics = result.metrics\n",
    "  print('round {:2d}, metrics={}'.format(round_num, train_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b707b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
